{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Goal\n",
    "# * Generate many functions. \n",
    "#     * Model the function with an MLP and fit with n epochs\n",
    "#     * Use the MLP to find $dydx$ and $d2y/d2x$ using `torch.autograd.grad`.\n",
    "#     * Use the  range of -1 to 1\n",
    "#     * Calculate the expected $dydx$ and $d2y/d2x$ for each function using sympy\n",
    "#     * Compare the L2 error between the analytical values and the MLP evaluted values for $dydx$ and $d2y/d2x$ \n",
    "#     * Record the error values \n",
    "#     * Plot the performance of the MLP to model the function and its deriviates\n",
    "# \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "from  sympy import *\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "from base import *\n",
    "from dataclasses import dataclass\n",
    "from dataclasses_json import dataclass_json\n",
    "from pathlib import Path\n",
    "\n",
    "do_step = Stepper()\n",
    "\n",
    "x = symbols(\"x\")\n",
    "\n",
    "def add(x1,x2): return x1-x2\n",
    "def minus(x1, x2): return x1-x2\n",
    "def power(x1, x2): return x1**x2\n",
    "def identity(x1): return x1\n",
    "\n",
    "\n",
    "fns = [cos, sin, identity]\n",
    "fns2 = [add, minus, power]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_equation(number_of_num_fncs):\n",
    "    y  = 1\n",
    "    for i in range(number_of_num_fncs):\n",
    "        if random.randint(0,1)==0:\n",
    "            # only requires 1 input. \n",
    "            fn = random.choice(fns)\n",
    "            y = y*fn(x)\n",
    "        else:\n",
    "            # requires 2 inputs. \n",
    "            fn = random.choice(fns2)\n",
    "            value = random.random()-0.5\n",
    "            # now choose if x is the input\n",
    "            if type(y)!=int and  y.has(x): # first, make sure y already has an x in its expression\n",
    "                if random.randint(0,1)==0:\n",
    "                    y = y*fn(x,value) # just use x as the input\n",
    "                else:\n",
    "                    print(f\"making composite, fn is {str(fn)} and  y = {y}\")\n",
    "                    y = fn(y,value) # do a composite function\n",
    "                    \n",
    "            else:\n",
    "                # if missing x in the express, then we need to use X for sure as the 1st input. \n",
    "                y = y*fn(x,value)\n",
    "#         print(i, y)\n",
    "\n",
    "    # catch the special case where everything cancels out. Just make the identity function\n",
    "    if type(y)==int or  y.has(x)== False:\n",
    "        print(f\"catching function with nothing {y}\")\n",
    "        y = x\n",
    "    return y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def make_whole_equation(possible_operations = 3, min_operations = 1):\n",
    "    number_of_num_fncs_numerator = random.randint(min_operations,possible_operations)\n",
    "    number_of_num_fncs_denominator = random.randint(min_operations,possible_operations)\n",
    "#     print(number_of_num_fncs_numerator,number_of_num_fncs_denominator )\n",
    "    numerator = make_equation(number_of_num_fncs_numerator)\n",
    "    denominator = make_equation(number_of_num_fncs_numerator)\n",
    "    equation = numerator/denominator\n",
    "    if type(equation)==int or  equation.has(x)== False:\n",
    "        print(f\"catching function with nothing {equation} within make_whole_equation\")\n",
    "        equation = x\n",
    "    print(f\"Equation is {equation}\")\n",
    "    return equation\n",
    "\n",
    "def get_y_values(equation, x_numeric):\n",
    "    \"\"\"get the y values evalued at x_numeric\"\"\"\n",
    "    f = lambdify(x, equation, \"numpy\")\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        y = f(x_numeric)\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def get_dydx_values(equation, x_numeric):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "    #     dydx = simplify( diff(equation, x))\n",
    "        dydx =  diff(equation, x)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        f_dydx = lambdify(x, dydx, \"numpy\")\n",
    "        dydx_values = f_dydx(x_numeric)\n",
    "        dydx_values = np.nan_to_num(dydx_values)\n",
    "    return dydx_values\n",
    "\n",
    "def get_d2yd2x_values(equation, x_numeric):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        dydx =  diff(equation, x)\n",
    "        d2yd2x =  diff(dydx, x)\n",
    "        f_d2yd2x = lambdify(x, d2yd2x, \"numpy\")\n",
    "        d2yd2x_values = f_d2yd2x(x_numeric)\n",
    "        d2yd2x_values = np.nan_to_num(d2yd2x_values)\n",
    "    return d2yd2x_values \n",
    "\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class Results:\n",
    "    fn_loss:float\n",
    "    dydx_loss:float\n",
    "    d2yd2x_loss:float\n",
    "    fn:str\n",
    "\n",
    "def make_file_name(idx, p):\n",
    "    return p / f\"result_{idx}.json\"\n",
    "\n",
    "def parse_file_name(fname):\n",
    "    i = fname.stem.find(\"_\")\n",
    "    return int(fname.stem[i+1:])\n",
    "\n",
    "def get_next_idx(folder):\n",
    "    files = list(folder.rglob(\"*.json\"))\n",
    "    idxs = [parse_file_name(f) for f in files]\n",
    "    if len(idxs)==0: \n",
    "        print(\"no saved results files found. returning 1\")\n",
    "        return 1\n",
    "    new_idx = max(idxs)+1\n",
    "    return new_idx\n",
    "\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class Config:\n",
    "    clip_value:int = 30 #clip eerything to be in the range \n",
    "    num_points_to_model:int = 50\n",
    "    num_equations:int = 5\n",
    "    folder:str = 'results'\n",
    "\n",
    "def run_loop(config ):\n",
    "    folder = Path(config.folder)\n",
    "    folder.mkdir(exist_ok=True)\n",
    "    x_numeric = np.linspace(-1,1, config.num_points_to_model)\n",
    "    for i in range(config.num_equations):\n",
    "        equation = make_whole_equation()\n",
    "        y = get_y_values(equation, x_numeric)\n",
    "        dydx_values = get_dydx_values(equation, x_numeric)\n",
    "        d2yd2x_values = get_d2yd2x_values(equation, x_numeric)\n",
    "\n",
    "        # make a torch version of the symbolically found dydx  \n",
    "        my_tensors  = [ dydx_values,d2yd2x_values, y]\n",
    "        dydx_values_true_t,d2yd2x_values_true_t, y = \\\n",
    "            [torch.clamp(torch.Tensor(v),-config.clip_value,config.clip_value) for v in my_tensors]\n",
    "\n",
    "\n",
    "        xb, yb = [make_batch(torch.tensor(np.nan_to_num(z))).to(torch.float32) for z in [x_numeric,y]]\n",
    "        yb_normalizer = Normalizer(yb)\n",
    "        yb_norm = yb_normalizer.norm(yb)\n",
    "\n",
    "        # ## Train the MLP\n",
    "        # * a learning rate higher than 1e-2 is generally unstable. \n",
    "        mlp = make_mlp(n = 100, layers_count=3, act = Mish)\n",
    "        do_step2 = Stepper_v2(mlp, xb, yb_norm)\n",
    "        do_step2.do_epochs(int(1e4), lr = 1e-4)\n",
    "        yprime = mlp(xb)\n",
    "\n",
    "        yprime_debatch = yb_normalizer.denorm(   debatch(yprime))\n",
    "\n",
    "        xb.requires_grad = True\n",
    "        yprime_pre = mlp(xb)\n",
    "        yprime_pre.retain_grad()\n",
    "        # yprime_pre.requires_grad = True\n",
    "        yprime = yb_normalizer.denorm(   yprime_pre)\n",
    "\n",
    "        dydx = torch.autograd.grad(yprime.sum(), xb, create_graph=True)[0]\n",
    "        d2yd2x = torch.autograd.grad(dydx.sum(), xb, create_graph=True)[0]\n",
    "\n",
    "        dydx, d2yd2x = [debatch(v) for v in [dydx, d2yd2x ]]\n",
    "        my_tensors  = [dydx, d2yd2x]\n",
    "        dydx, d2yd2x= [torch.clamp(v,-config.clip_value,config.clip_value) for v in my_tensors]\n",
    "\n",
    "        dydx_error = F.mse_loss(dydx_values_true_t,debatch(dydx))\n",
    "        d2yd2x_error = F.mse_loss(d2yd2x_values_true_t, d2yd2x)\n",
    "\n",
    "        r = Results(do_step2.loss_list[-1].item(), dydx_error.item(), d2yd2x_error.item(), str(equation))\n",
    "        j = r.to_json()\n",
    "        new_idx = get_next_idx(folder)\n",
    "        fname = make_file_name(new_idx,folder)\n",
    "        with open(fname, 'w') as f:\n",
    "            f.write(j)\n",
    "        print(f\"Finished {i}. Save name {fname} with equation {equation}\")\n",
    "    \n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     c = Config()\n",
    "#     run_loop(c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial3",
   "language": "python",
   "name": "tutorial3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
